# syntax=docker/dockerfile:1.4

# https://askubuntu.com/questions/972516/debian-frontend-environment-variable
ARG DEBIAN_FRONTEND=noninteractive


FROM wheels AS onnx-nvidia-wheels
COPY docker/onnx/requirements-nvidia.txt /requirements-nvidia.txt
RUN mkdir -p /onnx-nvidia-wheels && pip3 wheel --wheel-dir=/onnx-nvidia-wheels -r /requirements-nvidia.txt

FROM frigate AS frigate-nvidia-onnx

COPY --from=onnx-converter yolov8n.onnx ./
RUN --mount=type=bind,from=onnx-nvidia-wheels,source=/onnx-nvidia-wheels,target=/deps/onnx-nvidia-wheels \
    pip3 install -U /deps/onnx-nvidia-wheels/*.whl

# Add NVIDIA/CUDNN runtime directory to firgate runtime container, as CPU is good enough for dev
# Adapted from https://gitlab.com/nvidia/container-images/cuda/-/tree/master/templates/ubuntu
# Must match the requirements set out at
# https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements
# for onnxruntime==1.15

ENV NVARCH x86_64
ENV NVIDIA_REQUIRE_CUDA "cuda>=11.8 brand=tesla,driver>=450,driver<451 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471"
ENV NV_CUDA_CUDART_VERSION 11.8.89-1
ENV NV_CUDA_COMPAT_PACKAGE cuda-compat-11-8
ARG TARGETARCH

RUN apt-get update && apt-get install -y --no-install-recommends \
    gnupg2 curl ca-certificates && \
    curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/debian11/${NVARCH}/3bf863cc.pub | apt-key add - && \
    echo "deb https://developer.download.nvidia.com/compute/cuda/repos/debian11/${NVARCH} /" > /etc/apt/sources.list.d/cuda.list && \
    apt-get purge --autoremove -y curl \
    && rm -rf /var/lib/apt/lists/*

ENV CUDA_VERSION 11.8.0

RUN apt-get update && apt-get install -y --no-install-recommends \
    cuda-cudart-11-8=${NV_CUDA_CUDART_VERSION} \
    ${NV_CUDA_COMPAT_PACKAGE} \
    && rm -rf /var/lib/apt/lists/*

RUN echo "/usr/local/nvidia/lib" >> /etc/ld.so.conf.d/nvidia.conf \
    && echo "/usr/local/nvidia/lib64" >> /etc/ld.so.conf.d/nvidia.conf

ENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH}
ENV LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64

ENV NVIDIA_VISIBLE_DEVICES all
ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
# likely as "base-amd64"

# Install additional dependencies not listed in onnxruntime.ai/docs
ENV NV_CUDA_LIB_VERSION 11.8.0-1

# NCCL stripped from below, does not seem supported for debian
ENV NV_NVTX_VERSION 11.8.86-1
ENV NV_LIBNPP_VERSION 11.8.0.86-1
ENV NV_LIBNPP_PACKAGE libnpp-11-8=${NV_LIBNPP_VERSION}
ENV NV_LIBCUSPARSE_VERSION 11.7.5.86-1

ENV NV_LIBCUBLAS_PACKAGE_NAME libcublas-11-8
ENV NV_LIBCUBLAS_VERSION 11.11.3.6-1
ENV NV_LIBCUBLAS_PACKAGE ${NV_LIBCUBLAS_PACKAGE_NAME}=${NV_LIBCUBLAS_VERSION}

RUN apt-get update && apt-get install -y --no-install-recommends \
    cuda-libraries-11-8=${NV_CUDA_LIB_VERSION} \
    ${NV_LIBNPP_PACKAGE} \
    cuda-nvtx-11-8=${NV_NVTX_VERSION} \
    libcusparse-11-8=${NV_LIBCUSPARSE_VERSION} \
    ${NV_LIBCUBLAS_PACKAGE} \
    && rm -rf /var/lib/apt/lists/*

# Keep apt from auto upgrading the cublas package. See https://gitlab.com/nvidia/container-images/cuda/-/issues/88
RUN apt-mark hold ${NV_LIBCUBLAS_PACKAGE_NAME}


# Tested with CUDA versions from 11.6 up to 11.8, and cuDNN from 8.2.4 up to 8.7.0
ENV NV_CUDNN_VERSION 8.7.0.84
ENV NV_CUDNN_PACKAGE_NAME "libcudnn8"

ENV NV_CUDNN_PACKAGE "libcudnn8=$NV_CUDNN_VERSION-1+cuda11.8"

RUN apt-get update && apt-get install -y --no-install-recommends \
    ${NV_CUDNN_PACKAGE} \
    && apt-mark hold ${NV_CUDNN_PACKAGE_NAME} \
    && rm -rf /var/lib/apt/lists/*
# TODO Not sure if below necessary
RUN apt-get update && apt-get install -y curl \
    && rm -rf /var/lib/apt/lists/*

# Fixes a problem that seems specific to the cudnn version
RUN cd /usr/local/cuda-11.8/targets/x86_64-linux/lib/ && ln -s libnvrtc.so.11.2 libnvrtc.so
ENV LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/usr/local/cuda-11.8/targets/x86_64-linux/lib/"

#Disable S6 Global timeout
ENV S6_CMD_WAIT_FOR_SERVICES_MAXTIME=0

# # Dev Container w/ TRT
# FROM devcontainer AS devcontainer-onnx

# COPY --from=onnx-converter yolov8n.onnx ./
# RUN --mount=type=bind,from=onnx-wheels,source=/onnx-wheels,target=/deps/onnx-wheels \
#     pip3 install -U /deps/onnx-wheels/*.whl
